{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6194406",
   "metadata": {},
   "source": [
    "# Week 13 Workshop; Speeding Up PyTorch on a GPU VM\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand the benefits and engineering challenges of running PyTorch on GPUs for ML inference and training\n",
    "- Move existing PyTorch projects from CPU to GPU, using best practices for device management\n",
    "- Optimise data loading, batching, and throughput for GPU utilisation in HPC or cloud VMs\n",
    "- Debug, monitor, and resolve common hardware/software resource issues in GPU-accelerated environments\n",
    "- Prepare for individual assessments involving Azure GPU VMs and production-ready model development\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This hands-on lab will deepen your skills in GPU-accelerated machine learning using PyTorch. You will use industry tools and workflows relevant to cloud environments such as Azure, with a focus on practical application and troubleshooting. This experience prepares you for both immediate assessment tasks and industry-standard ML engineering roles.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup; Confirming GPU Availability\n",
    "\n",
    "Use these commands to check and validate whether your cloud VM or local environment has a supported GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Print device type; Expect 'cuda' if a supported GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Selected device;', device)\n",
    "\n",
    "# Print detected GPUs\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device count;', torch.cuda.device_count())\n",
    "    print('Current CUDA device;', torch.cuda.current_device())\n",
    "    print('CUDA device name;', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No CUDA-capable GPU detected. Check VM/driver setup.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf1352",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Run the code above. Record your device type and GPU details in your lab journal.\n",
    "- Troubleshoot if 'cuda' is not available; Check VM specs, driver state, and ask for support if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Moving Your Model and Data to GPU\n",
    "\n",
    "Learn how to move models and data between CPU and GPU for optimal performance; this is a key PyTorch workflow in both development and production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a35bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dummy model and tensor\n",
    "model = nn.Linear(512, 10)\n",
    "sample_data = torch.randn(16, 512)\n",
    "\n",
    "# Move both model and tensor to GPU (if available)\n",
    "model = model.to(device)\n",
    "sample_data = sample_data.to(device)\n",
    "\n",
    "# Forward pass\n",
    "output = model(sample_data)\n",
    "print('Output shape;', output.shape)\n",
    "print('Model and data on device;', output.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa3759",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Update any existing CPU-only scripts to use .to(device).\n",
    "- Reflect; What could go wrong if you forget to move data or model correctly?\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Comparing CPU vs GPU Performance\n",
    "\n",
    "Explore the impact of GPU acceleration by comparing CPU and GPU training times on a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "device_cpu = torch.device('cpu')\n",
    "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Simple model definition\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "# Random input and target\n",
    "input_data = torch.randn(1024, 512)\n",
    "target = torch.randint(0, 10, (1024,))\n",
    "\n",
    "# Define loss and optimizer\n",
    "def train_epoch(model, device):\n",
    "    model = model.to(device)\n",
    "    inputs = input_data.to(device)\n",
    "    targets = target.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(5):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Time on CPU\n",
    "cpu_model = SimpleNet()\n",
    "start = time.time()\n",
    "train_epoch(cpu_model, device_cpu)\n",
    "print('CPU time;', time.time() - start, 'seconds')\n",
    "\n",
    "# Time on GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    gpu_model = SimpleNet()\n",
    "    start = time.time()\n",
    "    train_epoch(gpu_model, device_gpu)\n",
    "    print('GPU time;', time.time() - start, 'seconds')\n",
    "else:\n",
    "    print('Skip GPU timing. No GPU available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d814f",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "- How much faster is GPU training in your environment?\n",
    "- What factors might affect speedup (model size, data copy speeds, batch size)?\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Optimising Data Loading and Batching\n",
    "\n",
    "Efficient data loading is critical for GPU throughput. Use DataLoader, batching, and pin_memory to optimise processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95583176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Simulate large dataset\n",
    "data = torch.randn(10000, 512)\n",
    "labels = torch.randint(0, 10, (10000,))\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Iterate and transfer batches to GPU\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    batch_data = batch_data.to(device, non_blocking=True)\n",
    "    batch_labels = batch_labels.to(device, non_blocking=True)\n",
    "    # Simulate training step..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46e264",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Tips**\n",
    "- Use suitable batch sizes to balance efficiency and memory constraints.\n",
    "- Enable pin_memory and non_blocking=True for faster data transfer from host to GPU.\n",
    "\n",
    "**Exercise**\n",
    "- Experiment with different batch sizes; Observe memory usage and training speed.\n",
    "- Document findings and best batch size for your model.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Monitoring and Debugging Resource Usage\n",
    "\n",
    "Use built-in and industry tools to track GPU memory, utilisation, and temperature.\n",
    "\n",
    "**Shell Command Example (run in terminal)**\n",
    "```\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "**In PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2774ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Allocated CUDA memory (MB);', torch.cuda.memory_allocated() // (1024*1024))\n",
    "    print('Max allocated CUDA memory (MB);', torch.cuda.max_memory_allocated() // (1024*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af095c",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Check GPU usage while running different batch sizes or models.\n",
    "- If you encounter OOM (Out of Memory) errors; Try reducing batch size, clearing cache (torch.cuda.empty_cache()), or simplifying the model.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Troubleshooting Checklist; Common Issues\n",
    "\n",
    "- CUDA device not detected; Restart VM, check driver install, validate instance type.\n",
    "- Data/model mismatch; Move ALL tensors/models to same device.\n",
    "- Out-of-memory errors; Lower batch size, monitor memory usage, clear GPU cache.\n",
    "- Kernel crash; Ensure only supported operations are run on GPU.\n",
    "- Performance plateau; Check data pipeline bottlenecks, experiment with pinned memory, and adjust dataloader workers.\n",
    "\n",
    "**Reflection**\n",
    "- Document a troubleshooting issue you encountered. Describe your steps to resolve it.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Industry Case Study; Real-World GPU Optimisation\n",
    "\n",
    "In AI product teams, moving workloads to GPU is a key step in scaling from prototype to production. For example, rapid model training on Azure GPU VMs allows data scientists to iterate faster and deploy models with higher accuracy.\n",
    "\n",
    "**Scenario**\n",
    "- A local software company used Azure NC-series VMs to cut their model training times from 12 hours to 40 minutes, resulting in rapid deployment and major cost savings. They used batch size tuning and resource monitoring best practices similar to those in this workshop.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Reflection and Assessment Questions\n",
    "\n",
    "- In 2-3 sentences, explain why it's important to optimise both data pipelines and compute pipelines when working with GPU VMs.\n",
    "- List two GPU troubleshooting techniques you might use before a major assessment or in an industry setting.\n",
    "- What are the ethical or cost considerations when scaling up GPU resources in commercial AI workflows?\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Summary and Next Steps\n",
    "\n",
    "- You have practiced key skills to move and optimise PyTorch workloads on GPUs, troubleshoot resource issues, and prepare for industry or assessment settings.\n",
    "- Next week, you will review these skills in the context of cloud infrastructure assessment and production model deployment.\n",
    "- Make sure your project scripts use robust device management techniques and document any performance bottlenecks discovered in this lab.\n",
    "- Review Azure GPU VM documentation before attempting your assessment project.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
