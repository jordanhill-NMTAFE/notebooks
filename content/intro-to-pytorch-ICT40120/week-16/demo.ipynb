{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfb385e",
   "metadata": {},
   "source": [
    "# Week 16 Demo; Complete Single-GPU Training Workflow in PyTorch\n",
    "\n",
    "## Introduction and Learning Objectives\n",
    "\n",
    "- Understand and implement the complete end-to-end deep learning pipeline using PyTorch on a single GPU.\n",
    "- Demonstrate clear evidence of competency for assessment, aligning with industry standards for documentation and reproducibility.\n",
    "- Reflect on the importance of code clarity, workflow structure, and best practices in ML engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6c9a4",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Setup; hardware and software preparation\n",
    "2. Data preparation; loading and pre-processing\n",
    "3. Model definition; PyTorch neural network modules\n",
    "4. Training loop; GPU device utilisation\n",
    "5. Model evaluation; metric calculation and result interpretation\n",
    "6. Checkpointing and saving artefacts\n",
    "7. Evidence gathering for assessment\n",
    "8. Industry alignment and reflection activities\n",
    "9. Troubleshooting and reproducibility best practices\n",
    "10. Wrap-up and next steps\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup; Hardware and Software Preparation\n",
    "\n",
    "- Ensure access to a GPU-enabled environment; e.g. Azure GPU VM, Kaggle notebook, or local hardware with CUDA.\n",
    "- Required software; Python 3.8+, PyTorch, Jupyter or Jupytext-compatible code editor.\n",
    "- Confirm PyTorch detects the GPU and set device before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU is available and PyTorch is using:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU detected; defaulting to CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb82544",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Preparation; Loading and Pre-processing\n",
    "\n",
    "- Use a standard dataset; e.g. MNIST or CIFAR-10 for demo clarity.\n",
    "- Apply typical transformations; normalization, conversion to tensors.\n",
    "- Demonstrate loading data with proper batching for GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667329f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data pre-processing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load dataset; here using MNIST as an example\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoaders for batching\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470bcd1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Model Definition; PyTorch Neural Network Construction\n",
    "\n",
    "- Define a simple neural network using PyTorch nn.Module.\n",
    "- Demonstrate moving model to GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c37cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and move to device\n",
    "model = SimpleMLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa8db2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Training Loop; GPU Device Utilisation\n",
    "\n",
    "- Set up an optimizer (e.g. Adam), loss criterion, and training loop.\n",
    "- Ensure all data and model computations are on the GPU.\n",
    "- Monitor and print training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training process\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # move to GPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}; Loss; {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69b16f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Model Evaluation; Metric Calculation and Result Interpretation\n",
    "\n",
    "- Evaluate accuracy on test set, explain metrics.\n",
    "- Move model to evaluation mode, disable gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test dataset; {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70c80c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Checkpointing and Saving Artefacts\n",
    "\n",
    "- Save trained model parameters for reproducibility and future use.\n",
    "- Demo the save and load process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'simplemlp_mnist.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model checkpoint saved at', model_path)\n",
    "\n",
    "# To load the model elsewhere:\n",
    "# model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c51431",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Evidence Gathering for Assessment\n",
    "\n",
    "- Document analytics output; loss curves, accuracy scores.\n",
    "- Take screenshots or download results for submission (per assessment guidance).\n",
    "- Ensure all code is well-commented and every stage includes markdown explanation.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Industry Alignment and Reflection Activities\n",
    "\n",
    "- Discuss typical industry workflows; why GPUs are essential for rapid experimentation.\n",
    "- Invite students to relate each demo step to a real-world deployment; e.g. 'How would you automate this pipeline on Azure or within an MLOps workflow?'\n",
    "- Example reflection question; What steps would you add to meet Responsible AI principles or model versioning standards?\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Troubleshooting and Reproducibility Best Practices\n",
    "\n",
    "- Common errors; CUDA out of memory, device mismatch, data loader bottlenecks.\n",
    "- Tips for avoiding workflow errors; always specify device, validate CUDA availability before batch jobs, log environment and library versions.\n",
    "- Encourage using script headers to auto-select device and warn on fallback.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Summary and Next Steps\n",
    "\n",
    "- Reviewed full cycle from data loading to evaluation on GPU using PyTorch.\n",
    "- Clear evidence required for assessment; annotated code, metric output, model artefacts.\n",
    "- Prepare for next week; multi-GPU workflows, distributed training, and scaling experiments.\n",
    "- Encourage saving your notebook and results for reassessment week if needed.\n",
    "\n",
    "---\n",
    "\n",
    "# Practical Exercise\n",
    "\n",
    "- Complete the MNIST end-to-end workflow as per the demo.\n",
    "- Experiment with model structure or optimizer; record and comment on the effect.\n",
    "- Generate an evidence report using screenshots, markdown summaries, and saved models for your assessment submission.\n",
    "\n",
    "---\n",
    "\n",
    "# Reflection and Assessment Preparation\n",
    "\n",
    "- How did single-GPU acceleration improve your training process?\n",
    "- What documentation or artifacts will you prepare for your assessment evidence?\n",
    "- Which best practices would you share with a new team member joining this workflow?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
