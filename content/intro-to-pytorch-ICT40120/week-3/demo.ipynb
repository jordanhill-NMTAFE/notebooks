{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f8ed01",
   "metadata": {},
   "source": [
    "# Week 3 Demo: From Pseudocode to Working Script - Data Automation Example\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workshop, you will learn to transform machine learning workflow requirements into actionable pseudocode, and then implement both Python and Bash scripts for real-world data automation tasks. The goal is to build confidence in designing and automating repeatable ML processes—a core skill for roles in AI development and engineering.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand how to break down ML data workflows into logical pseudocode steps.\n",
    "- Practice translating pseudocode into working Python and Bash scripts.\n",
    "- Collaborate to develop, test, and troubleshoot simple automation pipelines.\n",
    "- Prepare for future assessments by creating reusable templates and code patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. What is pseudocode and why do data engineers use it?\n",
    "2. Guided example; data pipeline in pseudocode, then script.\n",
    "3. Collaborative hands-on lab; convert, code, and test.\n",
    "4. Practical troubleshooting and best practices.\n",
    "5. Reflection and summary; how this skill connects to future topics.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Pseudocode for Data Pipelines\n",
    "\n",
    "Pseudocode is a human-friendly way to express logic before jumping into coding. It makes decomposing problems easier and helps verify your approach before scripting.\n",
    "\n",
    "**Why use pseudocode in ML workflows?**\n",
    "- Clarifies data movement and processing steps.\n",
    "- Simple to share and review with team members.\n",
    "- Eases translation across platforms or languages.\n",
    "\n",
    "**Example: Data Ingestion and Preprocessing Script (Pseudocode)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "1. Specify source location for dataset\n",
    "2. Check if dataset exists locally\n",
    "    - If not, download dataset from given URL\n",
    "3. Unzip or extract files if needed\n",
    "4. Preprocess data\n",
    "    - Remove missing or corrupted entries\n",
    "    - Normalize or scale relevant features\n",
    "5. Save cleaned data to output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb21a27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Translating Pseudocode to Python Script\n",
    "\n",
    "Let us turn the above pseudocode into a basic Python script for automating part of the ML workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1328e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Specify the source URL for dataset\n",
    "dataset_url = \"https://example.com/data/sample_dataset.zip\"\n",
    "local_zip_path = \"sample_dataset.zip\"\n",
    "extract_dir = \"data\"\n",
    "\n",
    "# 2. Check if dataset exists locally\n",
    "if not os.path.exists(local_zip_path):\n",
    "    print(\"Downloading dataset.\")\n",
    "    urllib.request.urlretrieve(dataset_url, local_zip_path)\n",
    "\n",
    "# 3. Unzip or extract\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(\"Extracting dataset.\")\n",
    "    with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "# 4. Preprocess data\n",
    "csv_path = os.path.join(extract_dir, \"sample_data.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.dropna()  # Remove missing entries\n",
    "df = (df - df.mean()) / df.std()  # Example normalization\n",
    "\n",
    "# 5. Save cleaned data\n",
    "df.to_csv(os.path.join(extract_dir, \"cleaned_data.csv\"), index=False)\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51533ef8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Translating Pseudocode to Bash Script\n",
    "\n",
    "Bash scripting can automate data operations in cloud and local environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 1. Specify source and destination\n",
    "DATASET_URL=\"https://example.com/data/sample_dataset.zip\"\n",
    "ZIP_FILE=\"sample_dataset.zip\"\n",
    "EXTRACT_DIR=\"data\"\n",
    "\n",
    "# 2. Check and download\n",
    "if [ ! -f \"$ZIP_FILE\" ]; then\n",
    "  echo \"Downloading dataset.\"\n",
    "  wget $DATASET_URL -O $ZIP_FILE\n",
    "fi\n",
    "\n",
    "# 3. Extract dataset\n",
    "if [ ! -d \"$EXTRACT_DIR\" ]; then\n",
    "  echo \"Extracting files.\"\n",
    "  unzip $ZIP_FILE -d $EXTRACT_DIR\n",
    "fi\n",
    "\n",
    "# 4. Preprocess (using csvkit for demo)\n",
    "csvcut -c 1,2,3 $EXTRACT_DIR/sample_data.csv > $EXTRACT_DIR/cleaned_data.csv\n",
    "\n",
    "echo \"Automation complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a02b65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Collaborative Coding and Review\n",
    "\n",
    "- Pair up and take turns; one writes pseudocode for a new automation task (e.g., fetch latest weather data), the other translates to Python or Bash.\n",
    "- Use shared online notebook or cloud shell for real-time feedback.\n",
    "- Discuss which steps are best suited for Bash vs Python, and why.\n",
    "- Experiment with adding error handling or logging.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Troubleshooting and Best Practices\n",
    "\n",
    "- Always check for file existence before downloads or writes.\n",
    "- Use descriptive variable names and inline comments.\n",
    "- Break large scripts into functions (Python) or well-named sections (Bash).\n",
    "- Document scripts for future users.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "- How does writing pseudocode improve your scripting workflow?\n",
    "- When would a Bash script be preferable to Python, and vice versa?\n",
    "- What would you do differently if running this pipeline in a cloud VM or HPC environment?\n",
    "\n",
    "---\n",
    "\n",
    "## Preparing for Assessment\n",
    "\n",
    "- Save your scripts; these can serve as templates for your Week 10 portfolio.\n",
    "- Practice translating between pseudocode, Python, and Bash to reinforce learning.\n",
    "- Reflect on how you could adapt these automation patterns to handle ML project data in Azure or HPC systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "- Today’s session introduced industry-style automation for ML using both Python and Bash, starting from clear logic in pseudocode.\n",
    "- Practice decomposing larger ML tasks into modular steps.\n",
    "- Next week, you will explore coding standards and version control for team-based development."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
