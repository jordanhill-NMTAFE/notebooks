{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e93990",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Week 15 Guided Lab\n",
    "## Handling a Large Dataset with HuggingFace Datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Gain practical experience loading and exploring extremely large datasets with HuggingFace Datasets tools.\n",
    "- Understand the workflow for scalable data processing in real-world AI projects.\n",
    "- Learn subset analysis, efficient filtering, and best practices for working with datasets used in LLM and generative AI contexts.\n",
    "- Develop troubleshooting skills when managing large-scale data and applying industry-standard documentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Instructor Setup and Introduction\n",
    "- Instructor introduces HuggingFace Datasets; explains why scalable tools are essential for modern AI workflows and data engineering teams.\n",
    "- Quick review of industry standards and open dataset documentation from previous weeks; highlights LAION, COCO, and similar datasets as real-world examples relevant to AI research organizations.\n",
    "\n",
    "---\n",
    "\n",
    "## Preparing the Environment [Markdown Cell]\n",
    "- Students confirm Python environment with essential libraries; instructor provides guidance or troubleshooting as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b08fae",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Required tools\n",
    "!pip install datasets pandas tqdm matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47445785",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- Instructor ensures every student can import and check versions. Encourages collaboration if issues arise.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1. Loading a HuggingFace Dataset [Markdown Cell]\n",
    "- Instructor demonstrates loading a popular large dataset such as COCO or Common Crawl (small subset due to computational limits); students replicate the code.\n",
    "- Emphasize how HuggingFace simplifies access to large datasets used in LLM model training or vision-language research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630975df",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a subset of the COCO dataset for demo purposes\n",
    "dataset = load_dataset('mstz/COCO', split='train[:1%]')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f30e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- Discuss dataset metadata, documentation, and license info using `dataset.info` attribute.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2. Exploring and Understanding Dataset Structure [Markdown Cell]\n",
    "- Instructor leads a guided tour of dataset fields, sample records, and annotations.\n",
    "- Students use preview commands; practice printing first few entries, and identifying image-caption data pairs (or equivalent structure for chosen dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cdf31",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Preview first few samples\n",
    "for i in range(3):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fffbe5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- Discuss typical fields needed for machine learning (features, targets) in the context of AI and generative models.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3. Subsetting and Filtering Large Datasets [Markdown Cell]\n",
    "- Demonstrate industry-relevant filtering such as removing corrupt records, or analyzing only samples that meet specific criteria (e.g., images with complex captions).\n",
    "- Students practice filtering, saving subsets for downstream AI tasks, and verifying results to align with open data best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b38a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Example: filter out samples with blank captions\n",
    "filtered = dataset.filter(lambda record: bool(record['caption']))\n",
    "print(f\"Filtered dataset size; {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d33f2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- Discuss impact on reproducibility and documentation; relate to data versioning and ethical curation from previous weeks.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4. Visualizing Dataset Statistics and Examples [Markdown Cell]\n",
    "- Instructor demonstrates how to quickly visualize key statistics (counts, distribution of caption length, simple bar charts).\n",
    "- Students generate plots and simple summary tables using matplotlib or pandas, applying industry-standard EDA techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd80d19",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "caption_lengths = [len(row['caption']) for row in filtered]\n",
    "plt.hist(caption_lengths, bins=20)\n",
    "plt.title('Distribution of Caption Lengths')\n",
    "plt.xlabel('Characters in Caption')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68871d0b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "- Reflection on why summary statistics matter for LLM and generative AI model training.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5. Advanced Task; Efficient Batch Processing [Markdown Cell]\n",
    "- Brief demo of batch-processing with HuggingFace for preprocessing or feature extraction (e.g., tokenizing captions for NLP), emphasizing memory efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6e938",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def process(record):\n",
    "    record['caption_length'] = len(record['caption'])\n",
    "    return record\n",
    "\n",
    "processed = filtered.map(process, batched=False)\n",
    "print(processed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453e87e",
   "metadata": {},
   "source": [
    "- Discuss why batch operations are preferred in industry pipelines and research workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting and Best Practices [Markdown Cell]\n",
    "- Instructor shares common pitfalls when working with large-scale datasets (e.g., memory errors, slow processing); students troubleshoot a simulated error (e.g., too large batch size).\n",
    "- Best practices; always check data types, handle missing values early, use sample splits for fast prototyping.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflection and Assessment Questions [Markdown Cell]\n",
    "- What are the key advantages of using industry tools such as HuggingFace Datasets for AI-scale data?\n",
    "- How can proper documentation and reproducible data filtering add value to a dataset used in real-world LLM research?\n",
    "- Describe a real industry scenario where subsetting and rapid EDA would be critical.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Next Steps [Markdown Cell]\n",
    "- Recap the importance of scalable, industry-standard tools for handling large datasets in AI roles.\n",
    "- Preview how these dataset skills support upcoming synthesis projects and knowledge-based assessment in Week 18.\n",
    "- Suggest students revisit their own project datasets and apply subsetting plus EDA techniques demonstrated today.\n",
    "  \n",
    "---\n",
    "\n",
    "## Extension Activity (Optional) [Markdown Cell]\n",
    "- Encourage advanced students to load or explore a different HuggingFace dataset (e.g., LAION, IMDB), document and share findings.\n",
    "- Prompt small groups to develop a mini case study; \"How would you document, filter, and prepare a massive dataset for a hypothetical generative AI project in an industry setting?\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
