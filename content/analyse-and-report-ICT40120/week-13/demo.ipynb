{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19cf9d4",
   "metadata": {},
   "source": [
    "# Week 13 Demo â€” Training a Simple Classifier on Open Data (Hands-On Guide)\n",
    "\n",
    "## Session Overview\n",
    "\n",
    "- Learn how to apply supervised machine learning basics using an open dataset with scikit-learn.\n",
    "- Gain practical experience in preparing data, splitting into train and test sets, training a simple model, and interpreting results.\n",
    "- Build skills directly relevant to industry datasets and upcoming assessments.\n",
    "- Emphasize reproducible, transparent, and ethical data workflows as required in modern AI roles.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "- Know how to load and inspect open datasets using Python and standard ML libraries.\n",
    "- Prepare data for classification tasks, including cleaning and visualization.\n",
    "- Split data for training and testing to prevent overfitting.\n",
    "- Train a simple classification model and evaluate its performance.\n",
    "- Interpret model outputs using industry-standard metrics.\n",
    "- Understand best practices for transparent, reproducible machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup and Preparation\n",
    "\n",
    "- Ensure you have Python 3.x, Jupyter Notebook, scikit-learn, pandas, matplotlib, and seaborn installed.\n",
    "- You can use Anaconda or pip; ask your lecturer if you need help with your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages if not already available\n",
    "!pip install scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f406f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load and Inspect an Open Dataset\n",
    "\n",
    "- For reproducibility in this demo, we use the famous \"Iris\" dataset, available directly from scikit-learn.\n",
    "- In industry, similar steps apply to larger or more complex datasets (e.g., CSVs, open repositories, HuggingFace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "\n",
    "# Inspect the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e0e52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Basic Data Exploration\n",
    "\n",
    "- Review dataset features and target (label).\n",
    "- Visualize class (species) distribution to check for class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Quick class distribution\n",
    "print(df['target'].value_counts())\n",
    "df['target'].plot(kind='hist', title='Class Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21644010",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Prepare and Split the Data\n",
    "\n",
    "- We split the data into features (X) and target labels (y).\n",
    "- Use train_test_split to create separate training and test sets (recommended industry practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4133ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Create 70/30 split for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf4292",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Train a Simple Classifier\n",
    "\n",
    "- Use DecisionTreeClassifier for interpretability and ease of use (industry-standard starting point).\n",
    "- Fit the classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b773bec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Evaluate Classifier Performance\n",
    "\n",
    "- Predict labels for the test set and evaluate performance using accuracy, confusion matrix, and classification report.\n",
    "- Discuss what these metrics mean and how they are used in industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26929389",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Interpret Results and Identify Pitfalls\n",
    "\n",
    "- Review metrics and discuss possible sources of error (overfitting, class imbalance, insufficient features).\n",
    "- Encourage students to consider ethical and transparent reporting (avoid overclaiming accuracy, document data prep and decisions).\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Practical Exercise\n",
    "\n",
    "- Adjust the max_depth hyperparameter of the DecisionTreeClassifier and observe any changes in accuracy.\n",
    "- Try using another model (e.g., LogisticRegression) and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tree depth\n",
    "model2 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "print(\"Accuracy with max_depth=2:\", accuracy_score(y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c1502",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Reflection and Industry Application\n",
    "\n",
    "- Discuss how similar steps are used in real AI projects for classifying large-scale data (images, text, etc.).\n",
    "- Highlight importance of transparent, well-documented processes for professional roles.\n",
    "- Prompt: What issues might occur with larger, messier real-world datasets? How could you address them?\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Troubleshooting and Best Practices\n",
    "\n",
    "- Always check for missing data and proper class balance before training.\n",
    "- Random seeds (random_state) ensure reproducibility.\n",
    "- Use comments and clear variable names; document all steps and decisions.\n",
    "- Save your notebook regularly and annotate key outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Summary and Next Steps\n",
    "\n",
    "- Today, you built a complete (if simple) supervised ML pipeline from data exploration to model evaluation.\n",
    "- Next week, you will work with more complex datasets and advanced model selection.\n",
    "- Review your notebook and practice repeating the workflow with another open dataset from scikit-learn (e.g., wine, breast cancer).\n",
    "- Prepare questions and challenges for discussion.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Assessment Link\n",
    "\n",
    "- The skills practiced today will be part of your Week 14 applied ML assessment using a UCI Machine Learning dataset.\n",
    "- Ensure you save your notebook and notes for future reference and possible reassessment."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
