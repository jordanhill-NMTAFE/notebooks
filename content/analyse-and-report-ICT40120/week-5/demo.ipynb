{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8170547f",
   "metadata": {},
   "source": [
    "# Week 5 Demo: Comparing Dataset Documentation – Practical Review\n",
    "\n",
    "## Setup and Introduction\n",
    "\n",
    "Welcome to Week 5; today, we will focus on analyzing and critiquing the documentation for two influential open datasets in AI. Understanding how datasets are described and documented is essential for transparency, reproducibility, and ethical AI work. You'll develop practical skills that are widely valued in industry AI and data science roles.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After this workshop, you'll be able to:\n",
    "- Explain the purpose and components of open dataset documentation.\n",
    "- Compare and critique documentation for two open datasets, referencing data standards.\n",
    "- Identify gaps, strengths, and best practices that support transparency and responsible data use.\n",
    "- Prepare for the critical review components of later assessments.\n",
    "\n",
    "---\n",
    "\n",
    "## Theoretical Context – Why Documentation Matters\n",
    "\n",
    "Dataset documentation is a fundamental industry standard. It ensures clarity on how data was collected, its intended use, potential biases, and legal or ethical constraints. Key documentation frameworks include:\n",
    "\n",
    "- Datasheets for datasets (Gebru et al.; covers motivation, composition, collection, recommended uses, and more)\n",
    "- Data cards (shorter summaries; focus on transparency and practical use in ML)\n",
    "\n",
    "Documentation allows AI professionals to evaluate whether a dataset suits a particular ML project, if it meets legal/ethical standards, and how it can be used safely and responsibly.\n",
    "\n",
    "---\n",
    "\n",
    "## Activity 1 – Reviewing Example Documentation\n",
    "\n",
    "We will review and compare documentation for two open datasets. For this exercise, let’s use:\n",
    "\n",
    "1. [COCO (Common Objects in Context)](https://cocodataset.org/#download)\n",
    "2. [LAION-5B (Large-scale AI Open Network)](https://laion.ai/blog/laion-5b/)\n",
    "\n",
    "**Task:**\n",
    "- Open both documentation pages in your browser.\n",
    "- Skim through the main sections:\n",
    "  - COCO: Overview, data composition, licensing, intended use, download links.\n",
    "  - LAION-5B: Collection methodology, filtering and quality metrics, ethical considerations, detailed technical info.\n",
    "\n",
    "List the key attributes described in both, and note any sections that feel underexplained or missing.\n",
    "\n",
    "---\n",
    "\n",
    "## Activity 2 – Tabular Comparison of Documentation Features\n",
    "\n",
    "In a markdown cell, make a table comparing key attributes found in each documentation:\n",
    "\n",
    "| Attribute                  | COCO                                 | LAION-5B                              |\n",
    "|----------------------------|--------------------------------------|---------------------------------------|\n",
    "| Dataset Purpose            |                                      |                                       |\n",
    "| Data Collection Process    |                                      |                                       |\n",
    "| Annotation Details         |                                      |                                       |\n",
    "| Licensing/Usage            |                                      |                                       |\n",
    "| Ethics Considerations      |                                      |                                       |\n",
    "| Known Bias or Limitations  |                                      |                                       |\n",
    "| Documentation Gaps         |                                      |                                       |\n",
    "\n",
    "*Fill in this table based on your review of the documentation.*\n",
    "\n",
    "---\n",
    "\n",
    "## Activity 3 – Best Practices and Gaps\n",
    "\n",
    "Consider the \"Datasheets for Datasets\" checklist. Discuss with a partner or reflect individually:\n",
    "\n",
    "- Which best practices are demonstrated by each documentation?\n",
    "  - Examples: Clear collection process. Transparent licensing. Disclosure of known issues.\n",
    "- What important information is missing?\n",
    "  - Examples: Lack of bias analysis. Missing advice on inappropriate use. Limited discussion on label accuracy.\n",
    "\n",
    "Write a brief summary (3–5 bullet points) of:\n",
    "- Best practices you observed\n",
    "- Information you wish had been included\n",
    "\n",
    "---\n",
    "\n",
    "## Activity 4 – Practical Python: Inspecting Dataset Metadata\n",
    "\n",
    "Many datasets on [HuggingFace Datasets](https://huggingface.co/datasets) include a standard metadata schema.\n",
    "\n",
    "Try this code cell to load metadata for the \"coco\" or an available dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load COCO's metadata where available (replace with specific dataset if needed)\n",
    "# Some datasets may not be directly available; substitute with any open dataset from Huggingface Datasets\n",
    "dataset = load_dataset(\"mstz/amazon_reviews_multi\", split=\"train\")\n",
    "print(dataset.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c692b8",
   "metadata": {},
   "source": [
    "**Tasks:**\n",
    "- Run the code, then inspect the printed metadata.\n",
    "- Compare what you see here with the dataset documentation. What extra information is embedded in the code-level metadata? What’s missing?\n",
    "- Discuss: How does programmatic metadata support or fail to support responsible dataset use?\n",
    "\n",
    "---\n",
    "\n",
    "## Activity 5 – Critical Reflection\n",
    "\n",
    "Answer these questions to reflect and prepare for assessment:\n",
    "\n",
    "- Why is transparent dataset documentation important for industry AI projects?\n",
    "- Name two risks of incomplete or poor documentation in open datasets.\n",
    "- How could you advocate for better documentation practice in your future workplace?\n",
    "\n",
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "In this demo, you explored and critiqued two open dataset documentation examples, learned to spot best practices and gaps, and examined how technical tools can support documentation standards. These skills prepare you for later assignments and for real-world data work in AI.\n",
    "\n",
    "**Next week:** We'll build on this by evaluating data quality and identifying bias in open datasets, using both manual and automated techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Datasheets for Datasets (Gebru et al.) – PDF](https://arxiv.org/abs/1803.09010)\n",
    "- [HuggingFace Dataset Card Guidelines](https://huggingface.co/docs/datasets/dataset_cards)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
