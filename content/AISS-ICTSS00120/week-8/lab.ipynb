{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0a9789",
   "metadata": {},
   "source": [
    "# Lab Sheet: Hyperparameter Tuning and Model Evaluation - Spam Email Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d38af9c",
   "metadata": {},
   "source": [
    "\n",
    "Similar and extension activities: https://github.com/justmarkham/pycon-2016-tutorial\n",
    "Kaggle alternative data set: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset\n",
    "\n",
    "### Objective:\n",
    "By the end of this lab, students will:\n",
    "- Understand the importance of hyperparameter tuning in machine learning.\n",
    "- Implement a spam email detection system using scikit-learn.\n",
    "- Perform hyperparameter tuning using GridSearchCV.\n",
    "- Evaluate the model's performance using various metrics.\n",
    "\n",
    "### Prerequisites:\n",
    "- Basic understanding of Python programming.\n",
    "- Familiarity with machine learning concepts and libraries (scikit-learn).\n",
    "- A working Python environment with necessary libraries installed.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Set Up the Environment:**\n",
    "   - Ensure `scikit-learn` is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f8360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c254fe",
   "metadata": {},
   "source": [
    "2. **Load the Dataset:**\n",
    "   - Download the spam dataset (e.g., SMS Spam Collection Dataset).\n",
    "   - Load the dataset into a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbcf545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Tension face 2. Smiling face 3. Waste face ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hhahhaahahah rofl was leonardo in your room or...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh for  sake she's in like</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No da:)he is stupid da..always sending like th...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lul im gettin some juicy gossip at the hospita...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms label\n",
       "0  1. Tension face 2. Smiling face 3. Waste face ...   ham\n",
       "1  Hhahhaahahah rofl was leonardo in your room or...   ham\n",
       "2                        Oh for  sake she's in like    ham\n",
       "3  No da:)he is stupid da..always sending like th...   ham\n",
       "4  Lul im gettin some juicy gossip at the hospita...   ham"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/jordanhill-NMTAFE/AISS-ICTSS00120/main/1%20Learning%20Materials/Week%208/sms.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Wrangle data into desired form\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"sms\"] = data[\"sms\"]\n",
    "\n",
    "# Label encoding\n",
    "df[\"label\"] = data[\"spam\"].map({False: \"ham\", True: \"spam\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075821d2",
   "metadata": {},
   "source": [
    "### Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90e1db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sms', 'spam', 'Unnamed: 3'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b9a13",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "3. **Preprocess the Data:**\n",
    "   - Clean and preprocess the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c3dc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"message\"] = df[\"message\"].apply(preprocess_text)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"message\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Vectorization\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb41d09",
   "metadata": {},
   "source": [
    "4. **Define the Model and Perform Hyperparameter Tuning:**\n",
    "   - Implement a simple model (e.g., Naive Bayes) and use GridSearchCV for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f39e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Define hyperparameters and GridSearchCV\n",
    "param_grid = {\"alpha\": [0.1, 0.5, 1.0, 1.5, 2.0]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c0e8a",
   "metadata": {},
   "source": [
    "5. **Evaluate the Model:**\n",
    "   - Transform the test data and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da53b7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "6. **Visualize Results:**\n",
    "   - Visualize the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Ham\", \"Spam\"],\n",
    "    yticklabels=[\"Ham\", \"Spam\"],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5300f",
   "metadata": {},
   "source": [
    "7. **Summary and Discussion:**\n",
    "   - Summarize the key steps taken during the lab.\n",
    "   - Discuss the model's performance, any challenges faced, and how they were addressed.\n",
    "\n",
    "### Deliverables:\n",
    "- A complete Jupyter notebook or code file with all implementations and visualizations.\n",
    "- Short write-up (in markdown cells within the notebook) summarizing findings, challenges, and learnings."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "AI_Skillset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
